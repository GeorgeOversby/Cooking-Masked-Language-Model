{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at ../artifacts and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(sys.path[0]).parent))\n",
    "from src.ingredient_tokenizer import load_tokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import RobertaForMaskedLM\n",
    "import numpy as np\n",
    "tokenizer = load_tokenizer('../artifacts')\n",
    "\n",
    "# model = RobertaForMaskedLM.from_pretrained('../artifacts', output_attentions=True)\n",
    "model = RobertaForMaskedLM.from_pretrained('../artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_head_view(model, tokenizer, text):\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention = model(input_ids)[-1]\n",
    "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "    head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention(texts, model, tokenizer):\n",
    "    inputs = tokenizer.batch_encode_plus(texts, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention = model(input_ids)[-1]\n",
    "    return np.stack([a.detach().numpy() for a in attention])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"salt sugar baking_soda lemon_juice flour egg shortening\",\n",
    "         \"salt sugar baking_soda flour molasses egg shortening\",\n",
    "         \"salt sugar baking_soda flour egg brown_sugar shortening\",\n",
    "         \"salt sugar baking_soda flour egg shortening buttermilk\",\n",
    "        ]\n",
    "attention = get_attention(texts, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer('salt sugar baking_soda lemon_juice flour egg shortening', return_tensors='pt')['input_ids']\n",
    "baking_sugar_vector = model(tokenized_input)[0][0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer('baking_soda sugar flour salt cookies ground_ginger ground_cloves molasses ground_cinnamon egg shortening', return_tensors='pt')['input_ids']\n",
    "baking_sugar_vector_2 = model(tokenized_input)[0][0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer('sugar mustard kidney_beans hamburger_buns sharp_white_cheddar_cheese water vegetable_oil gruyere_cheese sea_salt onions quinoa garlic butter ketchup chipotle_powder lettuce tomatoes freshly_ground_pepper mayonnaise cloves', return_tensors='pt')['input_ids']\n",
    "cooking_sugar_vector = model(tokenized_input)[0][0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer('sugar fish_sauce lime peas carrot salted_peanuts star_anise chile rice_wine_vinegar thai_basil chicken_stock garlic rice_stick_noodles cinnamon ginger scallions boneless_skinless_chicken_breast_halves canola_oil cloves mung_bean_sprouts', return_tensors='pt')['input_ids']\n",
    "cooking_sugar_vector_2 = model(tokenized_input)[0][0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8224, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(baking_sugar_vector, baking_sugar_vector_2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8807, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(cooking_sugar_vector, cooking_sugar_vector_2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7721, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(baking_sugar_vector, cooking_sugar_vector, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6976, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(baking_sugar_vector_2, cooking_sugar_vector, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7152, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(baking_sugar_vector_2, cooking_sugar_vector_2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8807, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(cooking_sugar_vector, cooking_sugar_vector_2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "recipes = []\n",
    "with open('../data/processed/recipes_val.txt') as f:\n",
    "    for recipe in f.readlines():\n",
    "        ings = recipe.split(' ')\n",
    "        if 'sugar' in ings:\n",
    "            tokenized_input = tokenizer(' '.join(ings), return_tensors='pt')['input_ids']\n",
    "            vector = model(tokenized_input)[0][0, ings.index('sugar')+1, :]\n",
    "            \n",
    "            vectors.append(vector.detach().numpy())\n",
    "            recipes.append(recipe)\n",
    "        \n",
    "        if len(vectors) > 500:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(vectors)\n",
    "clusters = kmeans.predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3505,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['flour salt vanilla_extract unsalted_butter cold_water sugar egg_yolk\\n'],\n",
       "       ['butter cream_cheese flour milk vanilla_extract margarine cherry_pie_filling cold_water cocoa sugar egg\\n'],\n",
       "       ['egg_yolks eggs salt milk cream sugar ground_cinnamon\\n'],\n",
       "       ['eggs flour salt milk zest unsalted_butter lemons sugar lemon_juice baking_powder\\n'],\n",
       "       ['vodka sugar goose lemon_juice triple_sec\\n'],\n",
       "       ['butter cooked_bacon eggs flour salt vanilla pecans unsweetened_cocoa_powder sugar bittersweet_chocolate\\n'],\n",
       "       ['cranberries syrup jello cream_cheese celery pineapple raspberry water grapes marshmallow_cream sugar relish heavy_whipping_cream dressing\\n'],\n",
       "       ['flour salt milk vanilla_extract unsalted_butter grated_nutmeg sugar active_dry_yeast egg_yolk\\n'],\n",
       "       ['butter nuts nutmeg flour salt eggs cinnamon water sugar cloves raisins pumpkin baking_soda\\n'],\n",
       "       ['butter nuts flour salt vanilla almond_extract sugar coconut egg\\n']],\n",
       "      dtype='<U309')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(recipes)[np.argwhere(clusters == 0)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['green_onions chicken_broth water white_wine_vinegar wild_rice vegetable_oil sugar curry_powder garlic_minced scallions shrimp\\n'],\n",
       "       ['salt onion garlic_cloves ancho pepper water bacon_grease sugar chili_powder tomatoes\\n'],\n",
       "       ['salt tomato_paste pizza_sauce pepper sugar spaghetti\\n'],\n",
       "       ['baking_soda jalapenos eggs salt buttermilk flour garlic_cloves honey sweet_onion egg_white corn_kernels sugar lime_juice chili_powder baking_powder frozen_corn yellow_cornmeal\\n'],\n",
       "       ['sugar yellow_mustard celery_salt pepper\\n'],\n",
       "       ['parsley salt olive_oil pepper dijon_mustard vegetable_oil red_wine_vinegar sugar shallots\\n'],\n",
       "       ['chili_oil garnish ginger eggs scallions black_vinegar ground_black_pepper cornstarch toasted_sesame_oil mushrooms soy_sauce bamboo_shoots sugar vegetable_oil firm_tofu garlic_minced vegetable_stock\\n'],\n",
       "       ['salt cooking_spray avocado chipotle_chile_powder corn_tortillas tuna lime_wedges sour_cream sugar cilantro_leaves chili_powder jalapeno sliced_onion ground_cumin\\n'],\n",
       "       ['bread_flour salt grated_parmesan_cheese black_pepper yeast cracked_wheat sugar wholewheat_flour artichoke_hearts hot_water\\n'],\n",
       "       ['salt bacon dry_mustard mushrooms oil poppy_seed white_vinegar sugar swiss_cheese red_onion spinach\\n']],\n",
       "      dtype='<U309')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(recipes)[np.argwhere(clusters == 1)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
